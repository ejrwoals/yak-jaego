"""
routes/data.py
ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ ë° ê´€ë¦¬ API Blueprint

ì—”ë“œí¬ì¸íŠ¸:
- GET  /data/manage                    - ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
- GET  /api/data-files                 - íŒŒì¼ ëª©ë¡ ì¡°íšŒ
- POST /api/check-data-file            - íŒŒì¼ ì¡´ì¬/ì›” ì •ë³´ í™•ì¸ (ì—…ë¡œë“œ ì „ ê²€ì‚¬)
- POST /api/upload-data-file           - íŒŒì¼ ì—…ë¡œë“œ
- POST /api/delete-data-file           - íŒŒì¼ ì‚­ì œ
- GET  /api/preview-data-file/<name>   - íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
- GET  /api/validate-data-file/<name>  - íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
"""

import os
import traceback
from datetime import datetime

from flask import Blueprint, render_template, request, jsonify
import pandas as pd

import paths
import drug_timeseries_db
from read_csv import extract_month_from_file
from routes.main import check_database_ready


data_bp = Blueprint('data', __name__)


# í—ˆìš©ëœ íŒŒì¼ í™•ì¥ì
ALLOWED_EXTENSIONS = {'csv', 'xls', 'xlsx'}


def allowed_file(filename):
    """íŒŒì¼ í™•ì¥ì ê²€ì¦"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@data_bp.route('/data/manage')
def data_manage():
    """ë°ì´í„° íŒŒì¼ ê´€ë¦¬ í˜ì´ì§€"""
    # DB ìƒíƒœ í™•ì¸
    is_ready, result = check_database_ready()
    db_stats = result if is_ready else None
    return render_template('data_manage.html', db_stats=db_stats)


@data_bp.route('/api/data-files')
def list_data_files():
    """data/ í´ë”ì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        data_path = paths.DATA_PATH

        # data/ í´ë”ê°€ ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ ë°˜í™˜
        if not os.path.exists(data_path):
            return jsonify({
                'files': [],
                'total_count': 0,
                'period': None
            })

        # CSV, XLS, XLSX íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        actual_files = []
        for filename in os.listdir(data_path):
            if filename.endswith(('.csv', '.xls', '.xlsx')):
                actual_files.append(filename)

        # DB ë©”íƒ€ë°ì´í„°ì™€ ì‹¤ì œ íŒŒì¼ ë™ê¸°í™” (self-healing)
        drug_timeseries_db.sync_data_files(actual_files, extract_month_from_file)

        # DBì—ì„œ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        file_metadata = drug_timeseries_db.get_data_files_metadata()

        files = []
        for filename in actual_files:
            file_path = os.path.join(data_path, filename)
            stat = os.stat(file_path)

            # DB ë©”íƒ€ë°ì´í„°ì—ì„œ ì›” ì •ë³´ ë° ì—…ë¡œë“œ ì¼ì‹œ ì¡°íšŒ
            if filename in file_metadata:
                month = file_metadata[filename]['month']
                uploaded_at = file_metadata[filename].get('uploaded_at')
            else:
                month = extract_month_from_file(filename)
                uploaded_at = None

            # íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
            size_bytes = stat.st_size
            if size_bytes < 1024:
                size_display = f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                size_display = f"{size_bytes / 1024:.1f} KB"
            else:
                size_display = f"{size_bytes / (1024 * 1024):.1f} MB"

            files.append({
                'filename': filename,
                'month': month,
                'size_bytes': size_bytes,
                'size_display': size_display,
                'file_modified_at': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                'uploaded_at': uploaded_at
            })

        # ì›” ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹ ì´ ìœ„ë¡œ)
        files.sort(key=lambda x: x['month'] or '', reverse=True)

        # íŒŒì¼ ê¸°ê°„ ì •ë³´ ê³„ì‚°
        file_months = [f['month'] for f in files if f['month']]
        period = None
        if file_months:
            sorted_months = sorted(file_months)
            period = {
                'start': sorted_months[0],
                'end': sorted_months[-1],
                'months': len(file_months)
            }

        # DB ì›” ëª©ë¡ ì¡°íšŒ
        db_months = []
        db_metadata = drug_timeseries_db.get_metadata()
        if db_metadata and 'month_list' in db_metadata:
            db_months = db_metadata['month_list']

        return jsonify({
            'files': files,
            'total_count': len(files),
            'period': period,
            'file_months': sorted(file_months) if file_months else [],
            'db_months': db_months
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@data_bp.route('/api/check-data-file', methods=['POST'])
def check_data_file():
    """ë°ì´í„° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ì›” ì •ë³´ í™•ì¸ (ì—…ë¡œë“œ ì „ ì‚¬ì „ ê²€ì‚¬)"""
    try:
        data = request.get_json()
        filename = data.get('filename', '')

        if not filename:
            return jsonify({'error': 'íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

        if not allowed_file(filename):
            return jsonify({'error': 'í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (CSV, XLS, XLSXë§Œ ê°€ëŠ¥)'}), 400

        # íŒŒì¼ëª…ì—ì„œ ì›” ì •ë³´ ì¶”ì¶œ
        month = extract_month_from_file(filename)
        if not month:
            # error í•„ë“œ ì—†ì´ valid: falseë§Œ ë°˜í™˜ â†’ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì›” ì„ íƒ ëª¨ë‹¬ í‘œì‹œ
            return jsonify({
                'valid': False,
                'filename': filename
            })

        # ë™ì¼ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        file_path = os.path.join(paths.DATA_PATH, filename)
        exists = os.path.exists(file_path)

        # ë™ì¼ ì›” ë‹¤ë¥¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        same_month_files = []
        if os.path.exists(paths.DATA_PATH):
            for f in os.listdir(paths.DATA_PATH):
                if f != filename and allowed_file(f):
                    f_month = extract_month_from_file(f)
                    if f_month == month:
                        same_month_files.append(f)

        return jsonify({
            'valid': True,
            'filename': filename,
            'month': month,
            'exists': exists,
            'same_month_files': same_month_files
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@data_bp.route('/api/upload-data-file', methods=['POST'])
def upload_data_file():
    """ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ - ì›ë³¸ íŒŒì¼ëª… ìœ ì§€, ë©”íƒ€ë°ì´í„° DB ì €ì¥"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400

        if not allowed_file(file.filename):
            return jsonify({'error': 'í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (CSV, XLS, XLSXë§Œ ê°€ëŠ¥)'}), 400

        # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í•œ ì›”ì´ ìˆëŠ”ì§€ í™•ì¸
        custom_month = request.form.get('month', '').strip()

        if custom_month:
            # ì‚¬ìš©ì ì§€ì • ì›” ì‚¬ìš©
            import re
            if not re.match(r'^\d{4}-\d{2}$', custom_month):
                return jsonify({'error': 'ì›” í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì˜ˆ: 2025-01)'}), 400
            month = custom_month
        else:
            # íŒŒì¼ëª…ì—ì„œ ì›” ì •ë³´ ì¶”ì¶œ
            month = extract_month_from_file(file.filename)
            if not month:
                return jsonify({'error': 'íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆ: 2025-01.xls, 202501.csv)'}), 400

        # data/ í´ë” ìƒì„± (ì—†ìœ¼ë©´)
        data_path = paths.DATA_PATH
        if not os.path.exists(data_path):
            os.makedirs(data_path)

        # íŒŒì¼ëª… ê²°ì •
        original_filename = file.filename
        _, ext = os.path.splitext(original_filename)

        # ì‚¬ìš©ìê°€ ì›”ì„ ì§ì ‘ ì§€ì •í•œ ê²½ìš°: íŒŒì¼ëª…ì„ YYYY-MM.í™•ì¥ìë¡œ í‘œì¤€í™”
        # (ì´í›„ ë¡œì§ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ ê°€ëŠ¥í•˜ë„ë¡)
        if custom_month:
            save_filename = f"{month}{ext}"
        else:
            save_filename = original_filename

        file_path = os.path.join(data_path, save_filename)

        # ë™ì¼ íŒŒì¼ëª…ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
        is_replacement = False
        if os.path.exists(file_path):
            # ê°™ì€ ì›” ë°ì´í„°ì¸ì§€ í™•ì¸
            existing_metadata = drug_timeseries_db.get_data_files_metadata()
            if save_filename in existing_metadata and existing_metadata[save_filename]['month'] == month:
                # ê°™ì€ ì›” ë°ì´í„° êµì²´
                is_replacement = True
            else:
                # ë‹¤ë¥¸ ì›” ë°ì´í„° - ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
                name_without_ext, ext = os.path.splitext(original_filename)
                counter = 1
                while os.path.exists(file_path):
                    save_filename = f"{name_without_ext}_{counter}{ext}"
                    file_path = os.path.join(data_path, save_filename)
                    counter += 1

        # íŒŒì¼ ì €ì¥
        file.save(file_path)

        # DBì— ë©”íƒ€ë°ì´í„° ì €ì¥
        drug_timeseries_db.add_data_file(save_filename, month)

        action = 'êµì²´' if is_replacement else 'ì—…ë¡œë“œ'
        manual_note = ' (ìˆ˜ë™ ì§€ì •)' if custom_month else ''
        print(f"ğŸ“ ë°ì´í„° íŒŒì¼ {action} ì™„ë£Œ: {save_filename}{manual_note}")

        return jsonify({
            'success': True,
            'filename': save_filename,
            'original_filename': original_filename,
            'month': month,
            'is_replacement': is_replacement,
            'is_manual': bool(custom_month),
            'message': f'{save_filename} íŒŒì¼ì´ {action}ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@data_bp.route('/api/delete-data-file', methods=['POST'])
def delete_data_file():
    """ë°ì´í„° íŒŒì¼ ì‚­ì œ"""
    try:
        data = request.get_json()
        filename = data.get('filename')

        if not filename:
            return jsonify({'error': 'íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

        # ë³´ì•ˆ: ê²½ë¡œ íƒìƒ‰ ë°©ì§€
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({'error': 'ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤.'}), 400

        # í™•ì¥ì ê²€ì¦
        if not allowed_file(filename):
            return jsonify({'error': 'í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'}), 400

        file_path = os.path.join(paths.DATA_PATH, filename)

        if not os.path.exists(file_path):
            return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        os.remove(file_path)

        # DBì—ì„œ ë©”íƒ€ë°ì´í„°ë„ ì‚­ì œ
        drug_timeseries_db.remove_data_file(filename)

        print(f"ğŸ—‘ï¸  ë°ì´í„° íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {filename}")

        return jsonify({
            'success': True,
            'message': f'{filename} íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@data_bp.route('/api/preview-data-file/<filename>')
def preview_data_file(filename):
    """ë°ì´í„° íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 10í–‰)"""
    try:
        # ë³´ì•ˆ: ê²½ë¡œ íƒìƒ‰ ë°©ì§€
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({'error': 'ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤.'}), 400

        if not allowed_file(filename):
            return jsonify({'error': 'í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'}), 400

        file_path = os.path.join(paths.DATA_PATH, filename)

        if not os.path.exists(file_path):
            return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        # íŒŒì¼ ì½ê¸°
        if filename.endswith('.csv'):
            # CSV: ì¸ì½”ë”© ì‹œë„
            df = None
            for encoding in ['utf-8', 'cp949', 'euc-kr']:
                try:
                    df = pd.read_csv(file_path, encoding=encoding, dtype={'ì•½í’ˆì½”ë“œ': str})
                    break
                except:
                    continue
            if df is None:
                return jsonify({'error': 'íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 400
        else:
            # Excel íŒŒì¼
            try:
                if filename.endswith('.xls'):
                    df = pd.read_excel(file_path, engine='calamine', dtype={'ì•½í’ˆì½”ë“œ': str})
                else:
                    df = pd.read_excel(file_path, engine='openpyxl', dtype={'ì•½í’ˆì½”ë“œ': str})
            except:
                df = pd.read_excel(file_path, dtype={'ì•½í’ˆì½”ë“œ': str})

        # ì „ì²´ í–‰ ìˆ˜
        total_rows = len(df)

        # ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 10í–‰)
        preview_df = df.head(10)

        # ì»¬ëŸ¼ëª…ê³¼ ë°ì´í„° ì¶”ì¶œ
        columns = preview_df.columns.tolist()
        rows = preview_df.fillna('').values.tolist()

        return jsonify({
            'success': True,
            'columns': columns,
            'rows': rows,
            'total_rows': total_rows,
            'preview_rows': len(rows)
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@data_bp.route('/api/validate-data-file/<filename>')
def validate_data_file(filename):
    """ë°ì´í„° íŒŒì¼ ìœ íš¨ì„± ê²€ì¦"""
    try:
        # ë³´ì•ˆ: ê²½ë¡œ íƒìƒ‰ ë°©ì§€
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({'error': 'ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤.'}), 400

        if not allowed_file(filename):
            return jsonify({'error': 'í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.'}), 400

        file_path = os.path.join(paths.DATA_PATH, filename)

        if not os.path.exists(file_path):
            return jsonify({'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        # ì›” ì •ë³´ í™•ì¸: DB ë©”íƒ€ë°ì´í„° ìš°ì„ , ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
        file_metadata = drug_timeseries_db.get_data_files_metadata()
        if filename in file_metadata:
            month = file_metadata[filename]['month']
        else:
            month = extract_month_from_file(filename)

        # íŒŒì¼ ì½ê¸° ì‹œë„
        df = None
        read_error = None

        if filename.endswith('.csv'):
            for encoding in ['utf-8', 'cp949', 'euc-kr']:
                try:
                    df = pd.read_csv(file_path, encoding=encoding, nrows=100, dtype={'ì•½í’ˆì½”ë“œ': str})
                    break
                except Exception as e:
                    read_error = str(e)
        else:
            try:
                if filename.endswith('.xls'):
                    df = pd.read_excel(file_path, engine='calamine', nrows=100, dtype={'ì•½í’ˆì½”ë“œ': str})
                else:
                    df = pd.read_excel(file_path, engine='openpyxl', nrows=100, dtype={'ì•½í’ˆì½”ë“œ': str})
            except Exception as e:
                read_error = str(e)

        if df is None:
            return jsonify({
                'valid': False,
                'month': month,
                'error': f'íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {read_error}',
                'required_columns': [],
                'present_columns': [],
                'missing_columns': [],
                'row_count': 0,
                'warnings': ['íŒŒì¼ ì½ê¸° ì‹¤íŒ¨']
            })

        # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        required_columns = ['ì•½í’ˆì½”ë“œ', 'ì•½í’ˆëª…', 'ì¬ê³ ìˆ˜ëŸ‰']
        present_columns = df.columns.tolist()
        missing_columns = [col for col in required_columns if col not in present_columns]

        # ê²½ê³  ë©”ì‹œì§€ ìƒì„±
        warnings = []
        if missing_columns:
            warnings.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing_columns)}")

        if month is None:
            warnings.append("íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ì „ì²´ í–‰ ìˆ˜ (100í–‰ë§Œ ì½ì—ˆìœ¼ë¯€ë¡œ ì‹¤ì œ í–‰ ìˆ˜ í™•ì¸ í•„ìš”)
        if filename.endswith('.csv'):
            for encoding in ['utf-8', 'cp949', 'euc-kr']:
                try:
                    full_df = pd.read_csv(file_path, encoding=encoding, dtype={'ì•½í’ˆì½”ë“œ': str})
                    row_count = len(full_df)
                    break
                except:
                    row_count = len(df)
        else:
            try:
                if filename.endswith('.xls'):
                    full_df = pd.read_excel(file_path, engine='calamine', dtype={'ì•½í’ˆì½”ë“œ': str})
                else:
                    full_df = pd.read_excel(file_path, engine='openpyxl', dtype={'ì•½í’ˆì½”ë“œ': str})
                row_count = len(full_df)
            except:
                row_count = len(df)

        return jsonify({
            'valid': len(missing_columns) == 0 and month is not None,
            'month': month,
            'required_columns': required_columns,
            'present_columns': present_columns,
            'missing_columns': missing_columns,
            'row_count': row_count,
            'warnings': warnings
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500
